[
    {
        "user_input": "What Device Farm do for run app?",
        "reference_contexts": [
            "This document explains how a simple Android Sample Application operates using the [Detr\\_resnet50\\_dc5](https://prd.ai-studio-farm.com/global/solution/ai/models/detail/a631921e-dc8b-46cb-ac17-d23c5a54db26) model optimized for Exynos hardware. **1\\. Functionality** This Sample Application identifies objects in images either from stored image files or input via the camera. Detected objects are highlighted with bounding boxes, and the label and score of each object are displayed. Additionally, the inference time is shown at the bottom of the application interface. ![](images/sample_application/phone_1.png) **2\\. Prerequisites** * To download [Android Studio](https://developer.android.com/studio), go to the official website and download it. * To run the Sample Application, clone the following repository. ```sh git clone https://github.com/exynos-eco/enn-sdk-samples-9925.git ``` * If there is no device available to run the application, you can use a real device provided in the Device Farm. For guidance on connecting a device in Android Studio, refer to the ADB proxy guide. **3. Starting Sample Application** * Open the cmd window and check if adb is connected. ```sh adb device List of devices attached 000011b58d246013 device ``` * Push a sample image for testing to the following path using adb push. ```sh adb push sample.jpg /storage/emulated/0/Pictures/ ``` * If the sample image is not visible after running the Sample Application, the media scanner may not have been updated, preventing the app from detecting the file. In this case, run the following command in adb shell to trigger media scanning. ```sh adb adb shell am broadcast -a android.intent.action.MEDIA_SCANNER_SCAN_FILE -d file:///storage/emulated/0/Pictures/sample.jpg ``` * After confirming a proper connection with Device Farm, select Tools \\-\\> Device Manager in Android Studio. ![](images/sample_application/device_manager_1.png) * After that check if the physical device is properly connected. ![](images/sample_application/samsung_electronics_1.png) * Run the Object Detection project from the Sample Applications obtained via git clone in Android Studio. ![](images/sample_application/object_detection_1.png) * When you select the object-detection project Android Studio will automatically perform a gradle sync. * The application in the selected project checks the connected device and runs when you click the Run button. ![](images/sample_application/run_1.png) * Select image mode and provide the data to be used for inference. ![](images/sample_application/camera_1.png) **4\\. I/O Specs** | INPUT | Description | Shape | Data Type | | :---: | :---: | :---: | :---: | | input | An RGB image | \\[1, 3, 480, 480\\] | float32 | | OUTPUT | Description | Shape | Data Type | | :---: | :---: | :---: | :---: | | output | Class score value | \\[1, 100, 92\\] | float32 | | 4363 | Show bounding box | \\[1, 100, 4\\] | Float32 | **5\\."
        ],
        "reference": "Device Farm provides a real device to run the application if there is no device available.",
        "synthesizer_name": "single_hop_specifc_query_synthesizer",
        "file": "C:\\Users\\User\\Downloads\\new_doc\\ECO25_GENERAL_Doc\\documentation\\eht.md",
        "retrieved_contexts": "",
        "response": "",
        "chatbot_response": "You are asking about the functionality of Device Farm for running applications.\nThe Device Farm is a service that allows developers to remotely manage and test their applications on various mobile devices. Here are the key features related to running apps in the Device Farm:\nRemote Access: Developers can access real devices remotely to test their applications, ensuring that they can evaluate performance and functionality accurately.\nDevice Selection: Users can choose from a variety of devices to run their applications, which helps in ensuring compatibility across different hardware and software configurations.\nRemote Control Functions: Once connected to a device, you can perform various actions such as uploading the application, managing files, using command shell access to run commands, and observing the app’s behavior in real-time.\nLog Management: The Device Farm provides the ability to view system logs and debugging information. This helps developers troubleshoot any issues that occur during the app execution.\nOverall, the Device Farm enhances the testing process by enabling developers to run their applications on real devices remotely, making it easier to identify and fix issues before deployment.\nIf you have more specific questions or need further information regarding the Device Farm, feel free to ask!",
        "date_time": "2025-03-17 14:06:04.454255+09:00",
        "chatbot_server": "https://prd.ai-studio-farm.com/global/chatbot"
    },
    {
        "user_input": "How do I replace the model file with Detr_resnet50_dc5 in the Object Detection Sample Application?",
        "reference_contexts": [
            "Object Detection Application Workflow** The Object Detection Sample Application follows these steps to produce results. 1. The model execution preparation sequence is as follows. 1-1. Initialize the framework using the ennInitialize function. 1-2. Load the ML model into the framework using the ennOpenModel function. 1-3. Allocate and commit the necessary buffers using the ennAllocateAllBuffers function. 2. The model execution sequence is as follows. 2-1. Set the input data as parameters. 2-2. Call the ennExecute function. 2-3. Receive the execution results. 3. The method for releasing the framework initialization is as follows. 3-1. Release the allocated memory of the buffers using the ennReleaseBuffers function. 3-2. Close the model and release other resources using the ennCloseModel function. 3-3. Deinitialize the framework using the ennDeinitialize function. ※ If you want to learn more about the detailed functions, please refer to the [Framework API](#bookmark=id.3o7alnk) at the bottom of the document. **6\\. Checklist when replacing model** 1\\. Model Filename (MODEL\\_NAME) * Replace the model file (Detr\\_resnet50\\_dc5) by adding it to the assets directory and entering the new model filename in the ModelConstants.kt file. ![](images/sample_application/android_assets_1.png) ![](images/sample_application/modelconstants_1.png) ```kotlin const val MODEL_NAME = \"detr_resnet50_dc5.nnc\" ``` 2. Change the input data type in ModelConstants.kt (INPUT_DATA_TYPE, INPUT_DATA_LAYER) * Other models may accept FLOAT32 format input, so verification is required. Check whether the input format is NHWC, HWC, or CHW before making changes. ```kotlin val INPUT_DATA_TYPE = DataType.FLOAT32 // Change it to the data type required by the model val INPUT_DATA_LAYER = LayerType.CHW // Change it to the layer required by the model ``` 3. Modify the input resolution (INPUT_SIZE_W, INPUT_SIZE_H, INPUT_SIZE_C) in ModelConstants.kt. * You must reflect the input resolution used by the model. ```kotlin const val INPUT_SIZE_W = 320 const val INPUT_SIZE_H = 320 const val INPUT_SIZE_C = 3 // If 3(RGB) ``` 4. Change the normalization method in ModelConstants.kt (INPUT\\_CONVERSION\\_SCALE, INPUT\\_CONVERSION\\_OFFSET) * You need to check and modify the normalization method used by the model. * Input normalization formula normalized_input = (raw_input−INPUT_CONVERSION_OFFSET)/INPUT_CONVERSION_SCALE ```kotlin const val INPUT_CONVERSION_SCALE = 255.0F // Scale the input data by 255 times const val INPUT_CONVERSION_OFFSET = 0.0F // Since the normalization formula is normalized\\_input \\= (raw\\_input−0.0)/255 any original pixel value, such as 0, 128, or 255, will always be normalized within the 0 to 1 range. ``` Deep learning models are designed to accept input data in the range of 0 to 1 or \\-1 to 1\\. 5\\. Output size in ModelConstants.kt (OUTPUT\\_SIZE\\_W, OUTPUT\\_SIZE\\_H) * Check and modify the output size of the model accordingly. ```kotlin const val OUTPUT_SIZE_W = 8400 const val OUTPUT_SIZE_H = 84 ``` 6\\. Class label file in ModelConstants.kt (LABEL_FILE) * If the model uses different class labels, a new .txt file must be provided in the assets directory. ```kotlin const val LABEL_FILE = \"detr_resnet50_dc5.txt\" ``` 7\\. Modify the preProcess() and postProcess() functions in the ModelExecutor.kt file located at the following path ![](images/sample_application/modelExecutor_1.png) * If the model's input or output data differs from the predefined format, modify the preProcess() and postProcess() functions accordingly. ```kotlin Class ModelExecutor -> preProcess(), postProcess() ``` **7\\. Compatible AI Models** * [Detr\\_resnet101\\_dc5](https://prd.ai-studio-farm.com/global/solution/ai/models/detail/9eb3e0fd-4478-49e4-b631-5941ce62d16c) * Face\\_det\\_lite * Foot\\_track\\_net * Yolov5"
        ],
        "reference": "To replace the model file with Detr_resnet50_dc5, you need to add the model file to the assets directory and enter the new model filename in the ModelConstants.kt file as follows: const val MODEL_NAME = \"detr_resnet50_dc5.nnc\". Additionally, ensure to change the input data type, modify the input resolution, adjust the normalization method, and check the output size in ModelConstants.kt. If the model uses different class labels, provide a new .txt file in the assets directory as well.",
        "synthesizer_name": "single_hop_specifc_query_synthesizer",
        "file": "C:\\Users\\User\\Downloads\\new_doc\\ECO25_GENERAL_Doc\\documentation\\eht.md",
        "retrieved_contexts": "",
        "response": "",
        "chatbot_response": "You are inquiring about replacing the model file with \"Detr_resnet50_dc5\" in the Object Detection Sample Application.\nTo replace the model file, follow these steps:\nLocate the Assets Directory: You need to add the new model file to the assets directory of your project.\nRename the Model File: Make sure that the new model file is named correctly. It should replace the existing model file (Detr_resnet50_dc5) with your new model file.\nUpdate Model Constants: In the application's code, locate the ModelConstants.kt file. You need to update the MODEL_NAME constant. Change it to reflect the name of the new model file you have added. For example:\nAdjust Input Data Type (if necessary): If the input data type or structure has changed with the new model, ensure you also update relevant sections in ModelConstants.kt regarding INPUT_DATA_TYPE and INPUT_DATA_LAYER.\nRebuild Your Application: Once you have made the changes, rebuild your application to ensure that the new model file is integrated properly.\nThis process will allow you to replace the model file successfully in the Object Detection Sample Application.\nIf you have further questions or need clarification on any specific step, feel free to ask!",
        "date_time": "2025-03-17 14:06:04.454255+09:00",
        "chatbot_server": "https://prd.ai-studio-farm.com/global/chatbot",
        "user_comment": "알려주는 https://prd.ai-studio-farm.com/global/development/enn-sdk/document/documentation#object-detection-sample-application 로 이동해서 보니 그림이 빨간색 테두리가 그냥 박스로 채워져 있네. 수정할 필요가 있음"
    },
    {
        "user_input": "How do I check if adb is connected in the command window?",
        "reference_contexts": [
            "This document explains how a simple Android Sample Application operates using the [Densenet121](https://prd.ai-studio-farm.com/global/solution/ai/models/detail/118f8cc6-f251-43b7-b8c2-ec77a3c50fda) model optimized for Exynos hardware. **1\\. Functionality** This application classifies objects in images either from stored image files or captured via the camera. The classified items, corresponding scores, and inference time are displayed at the bottom of the application interface. ![](images/sample_application/mouse.png) **2\\. Prerequisites** * To download [Android Studio](https://developer.android.com/studio), go to the official website and download it. * To run the Sample Application, clone the following repository. ```sh git clone https://github.com/exynos-eco/enn-sdk-samples-9945.git ``` * If there is no device available to run the application, you can use a real device provided in the Device Farm. For guidance on connecting a device in Android Studio, refer to the ADB proxy guide. **3\\. Starting Sample Application** * Open the cmd window and check if adb is connected. ```sh adb device List of devices attached 000011b58d246013 device ``` * Push a sample image for testing to the following path using adb push. ```sh adb push sample.jpg /storage/emulated/0/Pictures/ ``` * If the sample image is not visible after running the Sample Application, the media scanner may not have been updated, preventing the app from detecting the file. In this case, run the following command in adb shell to trigger media scanning. ```sh adb adb shell am broadcast -a android.intent.action.MEDIA_SCANNER_SCAN_FILE -d file:///storage/emulated/0/Pictures/sample.jpg ``` * After confirming a proper connection with Device Farm, select Tools \\-\\> Device Manager in Android Studio. ![](images/sample_application/device_manager_1.png) * After that check if the physical device is properly connected. ![](images/sample_application/samsung_electronics_1.png) * Run the Image Classification project from the Sample Applications obtained via git clone in Android Studio. ![](images/sample_application/image_classification_1.png) * When you select the image-classification project Android Studio will automatically perform a gradle sync. * The application in the selected project checks the connected device and runs when you click the Run button. ![](images/sample_application/run_1.png) * Select image mode and provide the data to be used for inference. ![](images/sample_application/camera_1.png) **4\\."
        ],
        "reference": "To check if adb is connected, open the cmd window and run the command `adb device`. This will display a list of devices attached, for example: `000011b58d246013 device`.",
        "synthesizer_name": "single_hop_specifc_query_synthesizer",
        "file": "C:\\Users\\User\\Downloads\\new_doc\\ECO25_GENERAL_Doc\\documentation\\eht.md",
        "retrieved_contexts": "",
        "response": "",
        "chatbot_response": "You want to know how to check if ADB is connected in the command window.\nTo verify if ADB (Android Debug Bridge) is connected, follow these steps:\nOpen Command Window: On your computer, open the command prompt (cmd). You can do this by searching for \"cmd\" in the Start menu (Windows) or Terminal (macOS/Linux).\nExecute ADB Command: Type the following command and press Enter:\nCheck the Output: If ADB is connected successfully, you will see a list of connected devices. The output will look something like this:\nIf you see your device listed, it means ADB is connected. If no devices are listed or you encounter an error, ensure that your device is properly connected with USB debugging enabled.\nIf you have any further questions or need additional assistance, feel free to ask!",
        "date_time": "2025-03-17 14:06:04.454255+09:00",
        "chatbot_server": "https://prd.ai-studio-farm.com/global/chatbot"
    },
    {
        "user_input": "Wht is the prpose of using Android in the development of image classification applications?",
        "reference_contexts": [
            "This guide provides a comprehensive overview for developing an image classification Android application using the Exynos Neural Network Software Development Kit (Exynos AI Studio).\nIt outlines the steps for creating an application that utilizes the Exynos AI Studio to run neural network models on Samsung Exynos hardware.\nThis guide covers the important steps that also include Android project setup, function implementation, and NNC model conversion.\nThe guide aims at equipping developers with the necessary knowledge to use the Exynos AI Studio in their Android applications."
        ],
        "reference": "The guide provides a comprehensive overview for developing an image classification Android application using the Exynos Neural Network Software Development Kit (Exynos AI Studio). It outlines the steps for creating an application that utilizes the Exynos AI Studio to run neural network models on Samsung Exynos hardware, covering important steps such as Android project setup, function implementation, and NNC model conversion.",
        "synthesizer_name": "single_hop_specifc_query_synthesizer",
        "file": "C:\\Users\\User\\Downloads\\new_doc\\ECO25_GENERAL_Doc\\documentation\\README.md",
        "retrieved_contexts": "",
        "response": "",
        "chatbot_response": "",
        "date_time": "2025-03-17 14:06:20.199948+09:00",
        "chatbot_server": "https://prd.ai-studio-farm.com/global/chatbot"
    },
    {
        "user_input": "How TFLite help in making neural network models work better on Samsung Exynos hardware, and what tools are used for this?",
        "reference_contexts": [
            "The [Exynos AI Studio](https://soc-developer.semiconductor.samsung.com/enn-sdk) provides a tool for converting [TFLite](https://www.tensorflow.org/lite) neural network models into models in Neural Network Container (NNC) format.\nThis conversion allows the NN models to operate efficiently on the [Samsung Exynos](https://semiconductor.samsung.com/processor/) hardware, to ensure optimal performance.\nThe Exynos AI Studio provides a framework that facilitates the execution of NNC models on the Exynos platform."
        ],
        "reference": "The Exynos AI Studio provides a tool for converting TFLite neural network models into models in Neural Network Container (NNC) format. This conversion allows the NN models to operate efficiently on the Samsung Exynos hardware, ensuring optimal performance.",
        "synthesizer_name": "single_hop_specifc_query_synthesizer",
        "file": "C:\\Users\\User\\Downloads\\new_doc\\ECO25_GENERAL_Doc\\documentation\\README.md",
        "retrieved_contexts": "",
        "response": "",
        "chatbot_response": "",
        "date_time": "2025-03-17 14:06:20.199948+09:00",
        "chatbot_server": "https://prd.ai-studio-farm.com/global/chatbot"
    },
    {
        "user_input": "How does the Exynos platform enhance the performance of AI applications?",
        "reference_contexts": [
            "The sample application takes input from a camera feed or an image, and classifies the object in the input.\nIt also leverages the Exynos AI Studio to efficiently execute the NN model on the Exynos platform."
        ],
        "reference": "The Exynos platform enhances the performance of AI applications by leveraging the Exynos AI Studio, which efficiently executes the NN model on the platform.",
        "synthesizer_name": "single_hop_specifc_query_synthesizer",
        "file": "C:\\Users\\User\\Downloads\\new_doc\\ECO25_GENERAL_Doc\\documentation\\README.md",
        "retrieved_contexts": "",
        "response": "",
        "chatbot_response": "",
        "date_time": "2025-03-17 14:06:20.199948+09:00",
        "chatbot_server": "https://prd.ai-studio-farm.com/global/chatbot"
    }
]